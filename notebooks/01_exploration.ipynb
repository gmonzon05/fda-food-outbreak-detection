{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA Food Adverse Events - Data Exploration\n",
    "\n",
    "This notebook explores the FDA openFDA food adverse event reports dataset to understand:\n",
    "- Dataset structure and quality\n",
    "- Temporal patterns in adverse event reports\n",
    "- Most common reactions and outcomes\n",
    "- Consumer demographics\n",
    "- Product categories involved\n",
    "\n",
    "**Goal**: Identify patterns that will inform our anomaly detection approach for outbreak identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom data loader\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_loader import FDADataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "\n",
    "We'll start by loading a subset of the data to explore its structure. The full dataset contains 2.6M+ records, so we'll initially work with a manageable sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_path = '../data/raw/food-event-0001-of-0001.json'\n",
    "loader = FDADataLoader(data_path)\n",
    "\n",
    "# Load sample of data (adjust max_records as needed)\n",
    "print(\"Loading data sample...\")\n",
    "df = loader.load_to_dataframe(max_records=50000)\n",
    "print(f\"Loaded {len(df):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names and types:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first few records\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Data Summary:\")\n",
    "print(missing_data[missing_data['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_cols = missing_data[missing_data['Missing_Percentage'] > 0].head(15)\n",
    "plt.barh(missing_cols['Column'], missing_cols['Missing_Percentage'])\n",
    "plt.xlabel('Missing Percentage (%)')\n",
    "plt.title('Missing Data by Column (Top 15)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate report numbers\n",
    "duplicates = df['report_number'].duplicated().sum()\n",
    "print(f\"Duplicate report numbers: {duplicates:,}\")\n",
    "print(f\"Unique reports: {df['report_number'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Analysis\n",
    "\n",
    "Understanding the time distribution of reports is crucial for outbreak detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_started to datetime\n",
    "df['date_started'] = pd.to_datetime(df['date_started'], errors='coerce')\n",
    "\n",
    "# Extract temporal features\n",
    "df['year'] = df['date_started'].dt.year\n",
    "df['month'] = df['date_started'].dt.month\n",
    "df['day_of_week'] = df['date_started'].dt.dayofweek\n",
    "df['quarter'] = df['date_started'].dt.quarter\n",
    "\n",
    "print(\"Date range:\")\n",
    "print(f\"Earliest: {df['date_started'].min()}\")\n",
    "print(f\"Latest: {df['date_started'].max()}\")\n",
    "print(f\"Missing dates: {df['date_started'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reports over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Daily counts\n",
    "daily_counts = df.groupby(df['date_started'].dt.date).size()\n",
    "axes[0].plot(daily_counts.index, daily_counts.values, alpha=0.7)\n",
    "axes[0].set_title('Daily Adverse Event Reports', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Number of Reports')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly counts\n",
    "monthly_counts = df.groupby(df['date_started'].dt.to_period('M')).size()\n",
    "monthly_counts.index = monthly_counts.index.to_timestamp()\n",
    "axes[1].plot(monthly_counts.index, monthly_counts.values, marker='o', linewidth=2)\n",
    "axes[1].set_title('Monthly Adverse Event Reports', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Number of Reports')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly trend\n",
    "yearly_counts = df['year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(yearly_counts.index, yearly_counts.values, color='steelblue')\n",
    "plt.title('Adverse Event Reports by Year', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Reports')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nYearly Report Counts:\")\n",
    "print(yearly_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reaction Analysis\n",
    "\n",
    "Identifying the most common reactions will help us focus our anomaly detection efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count reactions (handling lists)\n",
    "from collections import Counter\n",
    "\n",
    "all_reactions = []\n",
    "for reactions in df['reactions'].dropna():\n",
    "    if isinstance(reactions, list):\n",
    "        all_reactions.extend(reactions)\n",
    "    elif isinstance(reactions, str):\n",
    "        all_reactions.append(reactions)\n",
    "\n",
    "reaction_counts = Counter(all_reactions)\n",
    "top_reactions = pd.DataFrame(reaction_counts.most_common(30), \n",
    "                             columns=['Reaction', 'Count'])\n",
    "\n",
    "print(f\"Total unique reactions: {len(reaction_counts):,}\")\n",
    "print(f\"Total reaction occurrences: {len(all_reactions):,}\")\n",
    "print(\"\\nTop 30 Most Common Reactions:\")\n",
    "print(top_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top reactions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top 20 reactions\n",
    "top_20 = top_reactions.head(20)\n",
    "axes[0].barh(range(len(top_20)), top_20['Count'], color='coral')\n",
    "axes[0].set_yticks(range(len(top_20)))\n",
    "axes[0].set_yticklabels(top_20['Reaction'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Number of Reports')\n",
    "axes[0].set_title('Top 20 Most Common Adverse Reactions', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Top 10 with percentages\n",
    "top_10 = top_reactions.head(10).copy()\n",
    "top_10['Percentage'] = (top_10['Count'] / len(all_reactions) * 100).round(2)\n",
    "colors = plt.cm.Set3(range(len(top_10)))\n",
    "axes[1].pie(top_10['Count'], labels=top_10['Reaction'], autopct='%1.1f%%',\n",
    "           startangle=90, colors=colors)\n",
    "axes[1].set_title('Top 10 Reactions - Proportion', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outcome Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze outcomes\n",
    "all_outcomes = []\n",
    "for outcomes in df['outcomes'].dropna():\n",
    "    if isinstance(outcomes, list):\n",
    "        all_outcomes.extend(outcomes)\n",
    "    elif isinstance(outcomes, str):\n",
    "        all_outcomes.append(outcomes)\n",
    "\n",
    "outcome_counts = Counter(all_outcomes)\n",
    "outcome_df = pd.DataFrame(outcome_counts.most_common(), \n",
    "                         columns=['Outcome', 'Count'])\n",
    "outcome_df['Percentage'] = (outcome_df['Count'] / len(all_outcomes) * 100).round(2)\n",
    "\n",
    "print(\"Outcome Distribution:\")\n",
    "print(outcome_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outcomes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(outcome_df['Outcome'], outcome_df['Count'], color='teal')\n",
    "plt.title('Distribution of Adverse Event Outcomes', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Outcome Type')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Consumer Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age analysis\n",
    "age_data = df['consumer_age'].dropna()\n",
    "\n",
    "print(f\"Age statistics:\")\n",
    "print(f\"Mean: {age_data.mean():.1f} years\")\n",
    "print(f\"Median: {age_data.median():.1f} years\")\n",
    "print(f\"Min: {age_data.min():.1f} years\")\n",
    "print(f\"Max: {age_data.max():.1f} years\")\n",
    "print(f\"Std: {age_data.std():.1f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(age_data, bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Age (years)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Age Distribution of Consumers', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(age_data, vert=True)\n",
    "axes[1].set_ylabel('Age (years)')\n",
    "axes[1].set_title('Age Distribution - Box Plot', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "gender_counts = df['consumer_gender'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%',\n",
    "       startangle=90, colors=['lightcoral', 'lightskyblue', 'lightgray'])\n",
    "plt.title('Gender Distribution of Consumers', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGender Counts:\")\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top products/brands involved\n",
    "products = df['products'].dropna()\n",
    "product_list = []\n",
    "\n",
    "for prod in products:\n",
    "    if isinstance(prod, list):\n",
    "        product_list.extend(prod)\n",
    "    elif isinstance(prod, str):\n",
    "        product_list.append(prod)\n",
    "\n",
    "product_counts = Counter(product_list)\n",
    "top_products = pd.DataFrame(product_counts.most_common(20),\n",
    "                           columns=['Product', 'Count'])\n",
    "\n",
    "print(f\"Unique products: {len(product_counts):,}\")\n",
    "print(\"\\nTop 20 Products:\")\n",
    "print(top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top products\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(top_products)), top_products['Count'], color='mediumseagreen')\n",
    "plt.yticks(range(len(top_products)), top_products['Product'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Number of Reports')\n",
    "plt.title('Top 20 Products in Adverse Event Reports', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time Series by Reaction Type\n",
    "\n",
    "This is crucial for outbreak detection - we want to see how specific reactions trend over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot time series for specific reactions\n",
    "def plot_reaction_timeseries(df, reactions, freq='W'):\n",
    "    \"\"\"\n",
    "    Plot time series for specific reactions\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'date_started' and 'reactions'\n",
    "        reactions: List of reaction names to plot\n",
    "        freq: Frequency for aggregation ('D'=daily, 'W'=weekly, 'M'=monthly)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(reactions), 1, figsize=(15, 4*len(reactions)))\n",
    "    if len(reactions) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, reaction in enumerate(reactions):\n",
    "        # Filter for this reaction\n",
    "        reaction_mask = df['reactions'].apply(\n",
    "            lambda x: reaction in x if isinstance(x, list) else reaction == x\n",
    "        )\n",
    "        reaction_df = df[reaction_mask].copy()\n",
    "        \n",
    "        # Aggregate by time period\n",
    "        ts = reaction_df.groupby(pd.Grouper(key='date_started', freq=freq)).size()\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx].plot(ts.index, ts.values, linewidth=2)\n",
    "        axes[idx].set_title(f'Time Series: {reaction}', fontweight='bold', fontsize=12)\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].fill_between(ts.index, ts.values, alpha=0.3)\n",
    "    \n",
    "    axes[-1].set_xlabel('Date')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot top 5 reactions\n",
    "top_5_reactions = top_reactions.head(5)['Reaction'].tolist()\n",
    "plot_reaction_timeseries(df, top_5_reactions, freq='W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1. DATASET SIZE\")\n",
    "print(f\"   - Total records analyzed: {len(df):,}\")\n",
    "print(f\"   - Date range: {df['date_started'].min()} to {df['date_started'].max()}\")\n",
    "print(f\"   - Unique reports: {df['report_number'].nunique():,}\")\n",
    "\n",
    "print(f\"\\n2. REACTIONS\")\n",
    "print(f\"   - Unique reaction types: {len(reaction_counts):,}\")\n",
    "print(f\"   - Most common: {top_reactions.iloc[0]['Reaction']} ({top_reactions.iloc[0]['Count']:,} reports)\")\n",
    "print(f\"   - Top 5 reactions account for significant portion of reports\")\n",
    "\n",
    "print(f\"\\n3. TEMPORAL PATTERNS\")\n",
    "print(f\"   - Reports appear to have seasonal/temporal variation\")\n",
    "print(f\"   - Some spikes visible in time series plots\")\n",
    "print(f\"   - Further investigation needed for anomaly detection\")\n",
    "\n",
    "print(f\"\\n4. OUTCOMES\")\n",
    "if len(outcome_df) > 0:\n",
    "    print(f\"   - Most common outcome: {outcome_df.iloc[0]['Outcome']} ({outcome_df.iloc[0]['Percentage']:.1f}%)\")\n",
    "    print(f\"   - Serious outcomes present in dataset\")\n",
    "\n",
    "print(f\"\\n5. NEXT STEPS\")\n",
    "print(f\"   - Implement data preprocessing pipeline\")\n",
    "print(f\"   - Focus on top 10-20 reactions for anomaly detection\")\n",
    "print(f\"   - Develop baseline statistical models\")\n",
    "print(f\"   - Implement machine learning anomaly detectors\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data (Optional)\n",
    "\n",
    "Save the explored dataset for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to processed data folder\n",
    "output_path = '../data/processed/explored_sample.parquet'\n",
    "df.to_parquet(output_path, compression='snappy', index=False)\n",
    "print(f\"Saved explored data to: {output_path}\")\n",
    "print(f\"File size: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
